metric = EvalMetric,
trControl = TrainingControl)
return(TrainedModel)
})
return(AllModels)
}
AllModels <- fMultipleClassificationModels(TrainingData = dtTrain[,1:4],
TrainingLabels = dtTrain[,5],
TrainingControl = control,
EvalMetric = metric,
TrainingModels =  c("vglmAdjCat","lda","rpart","knn","svmRadial","rf","nb")
)
ClassificationResults <- resamples(list(LinClassifier = AllModels[[1]],
LDA = AllModels[[2]],
CART = AllModels[[3]],
knn = AllModels[[4]],
SVM = AllModels[[5]],
RF = AllModels[[6]],
NB = AllModels[[7]]))
summary(ClassificationResults)
dotplot(ClassificationResults)
print(fit.linClassifier)
print(fit.linClassifier$finalModel)
varImp(fit.linClassifier)
print(fit.linClassifier)
print(fit.linClassifier)
fit.linClassifier = AllModels[[1]]
print(fit.linClassifier)
summary(fit.linClassifier)
print(fit.linClassifier$finalModel)
varImp(fit.linClassifier)
dtTest <- data.table(dtTest)
dtTest[,predictedClass := predict(fit.linClassifier,newdata =  dtTest)]
confusionMatrix(dtTest[,predictedClass],dtTest[,Species])
9/10
10/11
20/21
29/30
library(rattle)
library(rpart)
library(rpart.plot)
library(party)
summary(Titanic)
head(Titanic)
head(Titanic)
Titanic[1,]
head(Titanic)
?Titanic
mosaicplot(Titanic, main = "Survival on the Titanic")
?Titanic
mosaicplot(Titanic)
mosaicplot(Titanic)
temp <- data.table(Titanic)
dtTitanic <- temp[as.numeric(rep(row.names(temp),temp$N)),] #0 frequency rows are gone now.
dtTitanic[,N := NULL]
#convert categorical variables into factors
dtTitanic[,Class := as.factor(Class)]
dtTitanic[,Sex := as.factor(Sex)]
dtTitanic[,Survived := as.factor(Survived)]
dtTitanic[,Age := as.factor(Age)]
summary(dtTitanic$Survived)
mosaicplot(dtTitanic)
mosaicplot(Titanic)
mosaicplot(Titanic)
mosaicplot(Titanic)
mosaicplot(Titanic)
summary(dtTitanic$Class)
summary(dtTitanic[Class == "Crew"]$Survived)
temp <- data.table(Titanic)
dtTitanic <- temp[as.numeric(rep(row.names(temp),temp$N)),] #0 frequency rows are gone now.
dtTitanic[,N := NULL]
#convert categorical variables into factors
dtTitanic[,Class := as.factor(Class)]
dtTitanic[,Sex := as.factor(Sex)]
dtTitanic[,Survived := as.factor(Survived)]
dtTitanic[,Age := as.factor(Age)]
summary(dtTitanic$Survived)
711/1490
711/(711 +1490)
library(qwraps2)
summary_table(dtTitanic)
summary_table(dtTitanic)
summary_table(dtTitanic,summary)
summary.table(dtTitanic)
library(dplyr)
summarise_all(dtTitanic)
?summarise_all
summarise_all(dtTitanic,summary)
library(papeR)
qsummary(dtTitanic)
qsummary(dtTitanic)
summary_table(dtTitanic,summaries = qsummary(dtTitanic))
summary_table(dtTitanic[,c(Class,Sex)])
summary_table(dtTitanic[,c("Class","Sex")])
summary_table(dtTitanic[,c("Class","Sex")])
kable(summary_table(dtTitanic[,c("Class","Sex")]))
library(knitr)
kable(summary_table(dtTitanic[,c("Class","Sex")]))
kable(summary_table(dtTitanic[,c("Class","Sex","Age")]))
summary_table(dtTitanic[,c("Class","Sex","Age")])
options(qwraps2_markdown = "markdown")
summary_table(dtTitanic[,c("Class","Sex","Age")])
temp <- data.table(Titanic)
dtTitanic <- temp[as.numeric(rep(row.names(temp),temp$N)),] #0 frequency rows are gone now.
dtTitanic[,N := NULL]
#convert categorical variables into factors
dtTitanic[,Class := as.factor(Class)]
dtTitanic[,Sex := as.factor(Sex)]
dtTitanic[,Survived := as.factor(Survived)]
dtTitanic[,Age := as.factor(Age)]
summary_table(dtTitanic[,c("Class","Sex","Age")])
options(qwraps2_markup = "markdown")
summary_table(dtTitanic[,c("Class","Sex","Age")])
summary_table(dtTitanic)
options(qwraps2_markup = "markdown")
summary(dtTitanic)
# lFormula <- paste0(names(dtTitanic)[4],"~",paste(names(dtTitanic)[1:3],collapse = "+"))
Titanic.cart <- train(Survived~Class+Sex+Age,
data = dtTitanicTrain,
method = "rpart",
trControl = control,
metric = metric)
fancyRpartPlot(Titanic.cart$finalModel)
#conditional tree
Titanic.ctree <- ctree(Survived~Class+Sex+Age,
data = dtTitanicTrain)
plot(Titanic.ctree)
lFormula <- paste0(names(dtTitanic)[4],"~",paste(names(dtTitanic)[1:3],collapse = "+"))
Titanic.tunedcart <- rpart(lFormula,
data = dtTitanicTrain)
rpart.plot(Titanic.tunedcart)
Titanic.tunedcart <- rpart(lFormula,
data = dtTitanicTrain,
control = rpart.control(maxdepth = 3))
rpart.plot(Titanic.tunedcart)
Titanic.tunedcart <- rpart(lFormula,
data = dtTitanicTrain,
control = rpart.control(maxdepth = 3,
minsplit = 10))
rpart.plot(Titanic.tunedcart)
lFormula
Titanic.tunedcart <- rpart(lFormula,
data = dtTitanicTrain,
control = rpart.control(maxdepth = 4,
minsplit = 10))
rpart.plot(Titanic.tunedcart)
Titanic.tunedcart <- rpart(lFormula,
data = dtTitanicTrain,
control = rpart.control(maxdepth = 4,
minsplit = 10,
cp = 0.005))
rpart.plot(Titanic.tunedcart)
summary(Titanic.tunedcart)
dtTitanicTest[,"predrpart"] <- predict(Titanic.tunedcart,dtTitanicTest,type = "class")
confusionMatrix(dtTitanicTest[,predrpart],dtTitanicTest[,Survived])
summary(Titanic.tunedcart)
predCtree <- predict(Titanic.ctree,dtTitanicTest)
confusionMatrix(predCtree,dtTitanicTest$Survived)
summary(Titanic.tunedcart)
305/309
60/(60+72)
?train
# lFormula <- paste0(names(dtTitanic)[4],"~",paste(names(dtTitanic)[1:3],collapse = "+"))
Titanic.cart <- train(Survived~Class+Sex+Age,
data = dtTitanicTrain,
method = "rpart",
trControl = control,
tunegrid =  expand.grid(cp = seq(0.01,0.005)),
metric = metric)
# lFormula <- paste0(names(dtTitanic)[4],"~",paste(names(dtTitanic)[1:3],collapse = "+"))
Titanic.cart <- train(Survived~Class+Sex+Age,
data = dtTitanicTrain,
method = "rpart",
trControl = control,
tunegrid =  expand.grid(cp = c(0.01,0.005)),
metric = metric)
c(0.01,0.005)
# lFormula <- paste0(names(dtTitanic)[4],"~",paste(names(dtTitanic)[1:3],collapse = "+"))
Titanic.cart <- train(Survived~Class+Sex+Age,
data = dtTitanicTrain,
method = "rpart",
trControl = control,
tunegrid =  expand.grid(cp = seq(from = 0.005,to = 0.01,by = 0.005)),
metric = metric)
# lFormula <- paste0(names(dtTitanic)[4],"~",paste(names(dtTitanic)[1:3],collapse = "+"))
Titanic.cart <- train(Survived~Class+Sex+Age,
data = dtTitanicTrain,
method = "rpart",
trControl = control
metric = metric)
# lFormula <- paste0(names(dtTitanic)[4],"~",paste(names(dtTitanic)[1:3],collapse = "+"))
Titanic.cart <- train(Survived~Class+Sex+Age,
data = dtTitanicTrain,
method = "rpart",
trControl = control,
metric = metric)
# lFormula <- paste0(names(dtTitanic)[4],"~",paste(names(dtTitanic)[1:3],collapse = "+"))
Titanic.cart <- train(Survived~Class+Sex+Age,
data = dtTitanicTrain,
method = "rpart",
trControl = control,
tuneGrid =  expand.grid(cp = c(0.005,0.01)),
metric = metric)
fancyRpartPlot(Titanic.cart$finalModel)
rpart.plot(Titanic.tunedcart)
fancyRpartPlot(Titanic.cart$finalModel)
(Titanic.cart)
#conditional tree
Titanic.ctree <- ctree(Survived~Class+Sex+Age,
data = dtTitanicTrain)
plot(Titanic.ctree)
fancyRpartPlot(Titanic.cart$finalModel)
confusionMatrix(predCtree,dtTitanicTest$Survived)
305+60
365/(305+60+72+4)
predcard <- predict(TTitanic.cart,dtTitanicTest)
predcard <- predict(Titanic.cart,dtTitanicTest)
confusionMatrix(predcart,dtTitanicTest$Survived)
predcart <- predict(Titanic.cart,dtTitanicTest)
confusionMatrix(predcart,dtTitanicTest$Survived)
365/(365+76)
View(Titanic.ctree)
plot(Titanic.ctree)
rpart.plot(Titanic.tunedcart)
plot(Titanic.ctree)
# lFormula <- paste0(names(dtTitanic)[4],"~",paste(names(dtTitanic)[1:3],collapse = "+"))
Titanic.cart <- train(Survived~Class+Sex+Age,
data = dtTitanicTrain,
method = "rpart",
trControl = control,
tuneGrid =  expand.grid(cp = c(0.005,0.01)),
metric = metric)
fancyRpartPlot(Titanic.cart$finalModel)
?fancyRpartPlot
(Titanic.cart)
dtTitanicTest[,"predictedClass"] <- predict(Titanic.tunedcart,
dtTitanicTest,
type = "class")
confusionMatrix(dtTitanicTest[,predictedClass],dtTitanicTest[,Survived])
library(titanic)
?`titanic-package`
titanic_test
library(titanic)
mosaicplot(titanic_train)
kable(head(titanic_train))
summary(titanic_train)
?titanic
?sonar
?Sonar
??Sonar
library(mlbench)
?Sonar
dtSonar <- data("Sonar")
View(dtSonar)
data("Sonar")
data(Sonar)
dtSonar <- data(Sonar)
dtSonar
Sonar
dtSonar <- Sonar
View(dtSonar)
dtSonar <- data.table(Sonar)
length(dtSonar)
nrow(dtSonar)
data("Sonar")
summary(Sonar)
boxplot(dtSonar[,1:60])
?boxplot
boxplot(dtSonar[,1:60],
xlab = "Frequency bin",
ylab = "Power spectral density (normalized)",
main = "Boxplots of all frequency bins")
summary(dtSonar$Class)
boxplot(dtSonar[Class == "M",1:60],
col = "blue",
xlab = "Frequency bin",
ylab = "Power spectral density (normalized)",
main = "Boxplots of all frequency bins")
par(new = T)
boxplot(dtSonar[Class == "R",1:60],
col = "green",
xlab = "Frequency bin",
ylab = "Power spectral density (normalized)",
main = "Boxplots of all frequency bins")
boxplot(dtSonar[Class == "M",1:60],
col = "blue",
xlab = "Frequency bin",
ylab = "Power spectral density (normalized)",
main = "Boxplots of all frequency bins")
par(new = T)
boxplot(dtSonar[Class == "R",1:60],
col = "green",
xlab = "Frequency bin",
ylab = "Power spectral density (normalized)",
main = "Boxplots of all frequency bins")
plot(dtSonar[Class == "M",1:60],
col = "blue",
xlab = "Frequency bin",
ylab = "Power spectral density (normalized)",
type = "l",
main = "Boxplots of all frequency bins")
plot(dtSonar[Class == "M",1:60],
col = "blue",
xlab = "Frequency bin",
ylab = "Power spectral density (normalized)",
main = "Boxplots of all frequency bins")
plot(dtSonar[Class == "M",1:60],
type = "l",
main = "Boxplots of all frequency bins")
boxplot(dtSonar[,1:60],
xlab = "Frequency bin",
ylab = "Power spectral density (normalized)",
main = "Boxplots of all frequency bins")
ggplot(dtSonar[,1]) + geom_histogram(aes(color = Class))
ggplot(dtSonar,aes(V1,color = Class)) + geom_histogram()
ggplot(dtSonar,aes(V1,color = Class)) + geom_boxplot()
ggplot(dtSonar[,1:10],aes(color = Class)) + geom_boxplot()
ggplot(dtSonar[,1:10],aes(names(dtSonar)[1:10],color = Class)) + geom_boxplot()
ggplot(dtSonar[,1:10],aes(V1,color = Class)) + geom_boxplot()
ggplot(dtSonar[,1],aes(V1,color = Class)) + geom_boxplot()
ggplot(dtSonar,aes(V1,color = Class)) + geom_histogram()
ggplot(dtSonar,aes(V1,color = Class)) + geom_boxplot()
#wide to long for colored boxplots
dtSonarTall <- melt(dtSonar,id.vars = c("Class"))
View(dtSonarTall)
names(dtSonarTall)
ggplot(data = dtSonarTall,aes(x = variable, y = value)) + geom_boxplot(aes(fill = Class))
dtSonar[,Rock := ifelse(Class == "R",1,0)]
dtSonar[,Mine := ifelse(Class == "M",1,0)]
library(data.table)
library(caret)
library(mlbench)
dtSonar <- data.table(Sonar)
library(mlbench)
dtSonar <- data.table(Sonar)
dtSonar <- data.table("Sonar")
data("Sonar")
dtSonar <- data.table(Sonar)
dtSonar <- data.table(data("Sonar"))
library(mlbench)
data("Sonar")
dtSonar <- data.table(Sonar)
rm(Sonar)
ggplot(dtSonar,aes(V1,color = Class)) + geom_boxplot()
#wide to long for colored boxplots
#ref: https://stackoverflow.com/questions/14604439/plot-multiple-boxplot-in-one-graph
dtSonarTall <- melt(dtSonar,id.vars = c("Class"))
ggplot(data = dtSonarTall,aes(x = variable, y = value)) + geom_boxplot(aes(fill = Class))
summary(dtSonar$Class)
# dtSonar[, Rock := ifelse(Class == "R",1,0)]
# dtSonar[, Mine := ifelse(Class == "M",1,0)]
dtSonar[,ClassNumeric := ifelse(Class == "M",1,0)]
fMultipleClassificationModels <- function(TrainingData, TrainingLabels, TrainingControl, EvalMetric, TrainingModels) {
AllModels <- lapply(TrainingModels, function(x) {
set.seed(3)
TrainedModel <- train(TrainingData,
TrainingLabels,
method = x,
metric = EvalMetric,
trControl = TrainingControl)
return(TrainedModel)
})
return(AllModels)
}
control <- trainControl(method = "cv",
number = 10)
fMultipleClassificationModels(TrainingData = dtSonar[,1:60],
TrainingLabels = dtSonar[,ClassNumeric],
TrainingControl = control,
EvalMetric = "accuracy",
TrainingModels = c("lda","rpart"))
fMultipleClassificationModels(TrainingData = dtSonar[,1:60],
TrainingLabels = dtSonar[,Class],
TrainingControl = control,
EvalMetric = "accuracy",
TrainingModels = c("lda","rpart"))
fMultipleClassificationModels(TrainingData = dtSonar[,1:60],
TrainingLabels = dtSonar[,Class],
TrainingControl = control,
EvalMetric = "accuracy",
TrainingModels = c("vglmAdjCat","lda","rpart","knn","svmRadial","rf","nb"))
#split data into test train
trainingIndex <- createDataPartition(dtSonar[,1],p = 0.8,list = FALSE)
#split data into test train
trainingIndex <- sample(seq(1:nrow(dtSonar)),0.8*nrow(dtSonar))
dtSonarTrain <- dtSonar[trainingIndex,]
dtSonarTest <- dtSonar[-trainingIndex,]
control <- trainControl(method = "cv",
number = 10)
metric <- "accuracy"
AllModelsSonar <- fMultipleClassificationModels(TrainingData = dtSonarTrain[,1:60],
TrainingLabels = dtSonarTrain[,Class],
TrainingControl = control,
EvalMetric = "accuracy",
TrainingModels = c("vglmAdjCat","lda","rpart","knn","svmRadial","rf","nb"))
ClassificationResults <- resamples(list(LinClassifier = AllModelsSonar[[1]],
LDA = AllModelsSonar[[2]],
CART = AllModelsSonar[[3]],
knn = AllModelsSonar[[4]],
SVM = AllModelsSonar[[5]],
RF = AllModelsSonar[[6]],
NB = AllModelsSonar[[7]]))
ClassificationResultsSonar <- resamples(list(LinClassifier = AllModelsSonar[[1]],
LDA = AllModelsSonar[[2]],
CART = AllModelsSonar[[3]],
knn = AllModelsSonar[[4]],
SVM = AllModelsSonar[[5]],
RF = AllModelsSonar[[6]],
NB = AllModelsSonar[[7]]))
summary(ClassificationResultsSonar)
dotplot(ClassificationResultsSonar)
library(keras)
SonarNN <- keras_model_sequential()
SonarNN %>% layer_dense(units = 60,activation = 'relu') %>% layer_dense(activation = 'sigmoid',units = 1)
SonarNN <- keras_model_sequential()
SonarNN %>% layer_dense(units = 60,activation = 'relu') %>% layer_dense(activation = 'sigmoid',units = 1)
SonarNN %>% compile(optimizer = 'adam',
loss = 'binary_crossentropy',
metrics = c('accuracy'))
?fit
SonarNN %>% fit(dtSonarTrain[,1:60],dtSonarTrain[,ClassNumeric],
epochs = 100,
batch_size = 5,)
SonarNN <- keras_model_sequential()
SonarNN %>% layer_dense(units = 60,activation = 'relu') %>% layer_dense(activation = 'sigmoid',units = 1)
SonarNN %>% compile(optimizer = 'adam',
loss = 'binary_crossentropy',
metrics = c('accuracy'))
SonarNN %>% fit(dtSonarTrain[,1:60],dtSonarTrain[,ClassNumeric],
epochs = 100,
batch_size = 5,)
SonarNN %>% fit(dtSonarTrain[,1:60],dtSonarTrain[,ClassNumeric],
epochs = 100,
batch_size = 5)
SonarNN %>% fit(dtSonarTrain[,1:60],dtSonarTrain[,ClassNumeric],
epochs = 100)
dtSonarTrain[,ClassNumeric]
dtSonarTrain[,1:60]
SonarNN %>% fit(dtSonarTrain[,1:60],
dtSonarTrain[,ClassNumeric],
epochs = 100,
batch_size = 5,
verbose = 2)
SonarNN %>% fit(dtSonarTrain[,1:60],
dtSonarTrain[,ClassNumeric],
validation_split = 0.2,
epochs = 100,
batch_size = 5,
verbose = 2)
getwd()
setwd("/home/nirzareevadgama/Projects/MLWithR")
library(data.table)
library(keras)
library(dplyr)
library(ggplot2)
library(purrr)
dtIMDB <- dataset_imdb(num_words = 10000)
dtTrain <- dtIMDB$train$x
dtTrainLabels <- dtIMDB$train$y
dtTest <- dtIMDB$test$x
dtTestLabels <- dtIMDB$test$y
# word_index <- dataset_imdb_word_index()
# dtWordIndex <- data.table(
#   word = names(word_index),
#   id = unlist(word_index,use.names = F)
# )
# reverse_word_index <- names(word_index)
# names(reverse_word_index) <- word_index
# decoded_review <- sapply(dtTrain[[1]],function(index) {
#   word <- if (index >= 3) reverse_word_index[[as.character(index - 3)]]
#   if (!is.null(word)) word else "?"
# })
#
# cat(decoded_review)
#one hot encode
onehotencode <- function(sequence) {
encoding  <- matrix(data = 0,nrow = length(sequence),ncol = 10000)
for (index in 1:length(sequence)) {
encoding[index,sequence[[index]]] <- 1
}
return(encoding)
}
x_train <- onehotencode(dtTrain)
y_test <- onehotencode(dtTest)
#convert labels from integer to numeric (todo: why so?)
x_labels <- as.numeric(dtTrainLabels)
y_labels <- as.numeric(dtTestLabels)
model <- keras_model_sequential() %>% layer_dense(units = 16,activation = 'relu',input_shape = c(10000)) %>% layer_dense(units = 16,activation = 'relu') %>% layer_dense(units = 1,activation = 'sigmoid')
#loss function and optimizer
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
#split train into train + validation
validation_indices <- 1:10000
x_val <- x_train[validation_indices,]
x_train_partial <- x_train[-validation_indices,]
x_labels_val <- x_labels[validation_indices]
x_labels_partial <- x_labels[-validation_indices]
history <- model %>% fit(
x_train_partial,
x_labels_partial,
epochs = 20,
batch_size = 512,
validation_data = list(x_val,x_labels_val)
)
x_labels
head(x_train)
head(x_train)
x_train[1]
x_train[1,]
