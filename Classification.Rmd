---
title: "Classification"
author: "Nirzaree"
date: "09/07/2020"
output: html_document
---

recap
load data
plot
split into train test
apply different models
linear classifier
LDA
decision trees (rpart)
knn
svmradial
random forest
plot results 
predict on best model 

functions used: 
1. plotting: featurePlot
2. split train test: createDataPartition
3. fitting models: train 
4. viewing 
3. predicting: predict

config in train: 
train(trainingdata, traininglabels,method, metric, control)
method = "vglmAdjCat":linear classifier, "rpart" : decision trees,"knn","lda","svmRadial","rf"
metric = "accuracy"
control = trainControl(method = "cv", number = 10)

Q: 
Classification models : 
Why are they useful here? 

What do we check to make sure its not misleading? 
How do we choose the validation metric here? 



```{r setup,include=FALSE,echo = FALSE, message = FALSE, warning = FALSE,fig.width = 16, fig.height = 10}
library(data.table)
library(caret)
```

```{r loadDataSet,include=FALSE,echo = FALSE, message = FALSE, warning = FALSE,fig.width = 16, fig.height = 10}
#iris is already loaded
data(iris)
```

```{r basicSummary,include=FALSE,echo = FALSE, message = FALSE, warning = FALSE,fig.width = 16, fig.height = 10}
summary(iris)
```

```{r basicPlots,include=FALSE,echo = FALSE, message = FALSE, warning = FALSE,fig.width = 16, fig.height = 10}
featurePlot(iris[,1:4],iris[,5],"pairs")

featurePlot(iris[,1:4],iris[,5],"box")

# featurePlot(iris[,1:4],iris[,5],"ellipse")

featurePlot(iris[,1:4],iris[,5],"density")
```
**Observation**: Petal Width & Length are good features. Sepal length okayish and sepal width very good. 

```{r Classifiermodel_splitData,include=FALSE,echo = FALSE, message = FALSE, warning = FALSE,fig.width = 16, fig.height = 10}

#split data into test train 
trainingIndex <- createDataPartition(iris[,5],p = 0.8,list = FALSE)

dtTrain <- iris[trainingIndex,]
dtTest <- iris[-trainingIndex,]

```

```{r Classifiermodel_config,include=FALSE,echo = FALSE, message = FALSE, warning = FALSE,fig.width = 16, fig.height = 10}
control <- trainControl(method = "cv",number = 10)
metric <- "accuracy"
```

Models to be tried out:
1. Linear Classifier
2. LDA
3. CART
4 kNN
5. SVM
6. RF

```{r Classifiermodel_tryModels,include=FALSE,echo = FALSE, message = FALSE, warning = FALSE,fig.width = 16, fig.height = 10}
#1. Linear Model
set.seed(3)
fit.linClassifier <- train(dtTrain[,1:4],
                           dtTrain[,5],
                           method = "vglmAdjCat",
                           metric = metric,
                           trControl = control)

set.seed(3)
fit.lda <- train(dtTrain[,1:4],
                 dtTrain[,5],
                 method = "lda",
                 metric = metric,
                 trControl = control)

set.seed(3)
fit.cart <- train(dtTrain[,1:4],
                 dtTrain[,5],
                 method = "rpart",
                 metric = metric,
                 trControl = control)

set.seed(3)
fit.knn <- train(dtTrain[,1:4],
                 dtTrain[,5],
                 method = "knn",
                 metric = metric,
                 trControl = control)

set.seed(3)
fit.svm <- train(dtTrain[,1:4],
                 dtTrain[,5],
                 method = "svmRadial",
                 metric = metric,
                 trControl = control)

set.seed(3)
fit.rf <- train(dtTrain[,1:4],
                 dtTrain[,5],
                 method = "rf",
                 metric = metric,
                 trControl = control)
```

```{r CheckModelAccuracy,include=FALSE,echo = FALSE, message = FALSE, warning = FALSE,fig.width = 16, fig.height = 10}
ClassificationResults <- resamples(list(LinClassifier = fit.linClassifier,
                                        LDA = fit.lda,
                                        CART = fit.cart,
                                        knn = fit.knn,
                                        SVM = fit.svm,
                                        RF = fit.rf))

summary(ClassificationResults)
dotplot(ClassificationResults)
```

```{r InvestigateTheWinningModel,include=FALSE,echo = FALSE, message = FALSE, warning = FALSE,fig.width = 16, fig.height = 10}
print(fit.lda)

```

```{r predictOnValidationSet,include=FALSE,echo = FALSE, message = FALSE, warning = FALSE,fig.width = 16, fig.height = 10}
dtTest <- data.table(dtTest)
dtTest[,predictedClass := predict(fit.lda,newdata =  dtTest)]

confusionMatrix(dtTest[,predictedClass],dtTest[,Species])
```

**Summary:**
