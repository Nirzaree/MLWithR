---
title: "Clustering"
author: "Nirzaree"
date: "10/07/2020"
output: html_document
---

```{r setup}
library(data.table)
library(VIM)
library(lubridate)
library(leaflet)
```

```{r loadData}
apr14 <- read.csv("https://raw.githubusercontent.com/fivethirtyeight/uber-tlc-foil-response/master/uber-trip-data/uber-raw-data-apr14.csv")
may14 <- read.csv("https://raw.githubusercontent.com/fivethirtyeight/uber-tlc-foil-response/master/uber-trip-data/uber-raw-data-may14.csv")
jun14 <- read.csv("https://raw.githubusercontent.com/fivethirtyeight/uber-tlc-foil-response/master/uber-trip-data/uber-raw-data-jun14.csv")
jul14 <- read.csv("https://raw.githubusercontent.com/fivethirtyeight/uber-tlc-foil-response/master/uber-trip-data/uber-raw-data-jul14.csv")
aug14 <- read.csv("https://raw.githubusercontent.com/fivethirtyeight/uber-tlc-foil-response/master/uber-trip-data/uber-raw-data-aug14.csv")
sep14 <- read.csv("https://raw.githubusercontent.com/fivethirtyeight/uber-tlc-foil-response/master/uber-trip-data/uber-raw-data-sep14.csv")
```

```{r PreProcess}
#bind data
dtUberData <- data.table(rbind(apr14,may14,jun14,jul14,aug14,sep14))
rm(apr14,may14,jun14,jul14,aug14,sep14)

summary(dtUberData)

head(dtUberData)

#check missing data
aggr(dtUberData)

#format time data
#always check first. :| NAs due to any reasons require download of all data again.
dtUberData[,Date.Time := mdy_hms(Date.Time)]

#make separate cols for various time fields
dtUberData[,Year := factor(year(Date.Time))]
dtUberData[,Month := factor(month(Date.Time))]
dtUberData[,Date := factor(date(Date.Time))]
dtUberData[,WorkingDay := factor(wday(Date.Time))]
dtUberData[,Hour := factor(hour(Date.Time))]
dtUberData[,Min := factor(minute(Date.Time))]
dtUberData[,Sec := factor(second(Date.Time))]

```

```{r plotData}
# leaflet hangs when trying to plot such huge data. dont even try
# leaflet() %>% addTiles() %>% addMarkers(lng = dtUberData[,Lon],lat = dtUberData[,Lat])
```

```{r Model}
#try with different clusters

```

```{r Predict}

```

